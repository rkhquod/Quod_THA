NeuralNet:
  batch_size: 256
  dropout_rate: 0.2
  epochs: 100
  hidden_dim: 100
  input_dim: 21
  loss: L1Loss
  lr: 2.0e-05
  optimizer: Adam
  output_dim: 1
  patience: 10
  print_per_epoch: 1
